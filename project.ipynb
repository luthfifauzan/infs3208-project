{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44896823-bfa0-4e49-82a9-32645c5f5ec9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f387406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyshp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b80dade1-b05a-45f7-a628-a3fa327389ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# spark libraries\n",
    "from pyspark import SparkConf \n",
    "from pyspark.context import SparkContext \n",
    "from pyspark.sql import * \n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.functions import date_format\n",
    "from pyspark.sql.types import * \n",
    "\n",
    "#additional libraries\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import shapefile as shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeaf7009-5dfe-475b-9149-ae733f395f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# addtional function to convert incompatibility in timestamp values between spark & pandas\n",
    "# https://stackoverflow.com/a/76947136\n",
    "def convert_to_pandas(spark_df):\n",
    "    \"\"\"\n",
    "    This function will safely convert a spark DataFrame to pandas.\n",
    "    \"\"\"\n",
    "    # Iterate over columns and convert each timestamp column to a string\n",
    "    timestamp_cols = []\n",
    "    for column in spark_df.schema:\n",
    "        if column.dataType == TimestampType():\n",
    "            # Append column header to list\n",
    "            timestamp_cols.append(column.name)\n",
    "            # Set column to string using date_format function\n",
    "            spark_df = spark_df.withColumn(\n",
    "                column.name,\n",
    "                date_format(column.name, \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    # Convert to a pandas DataFrame and reset timestamp columns\n",
    "    pandas_df = spark_df.toPandas()\n",
    "    for column_header in timestamp_cols:\n",
    "        pandas_df[column_header] = pandas_df[\n",
    "            column_header].astype(\"datetime64[ns]\")\n",
    "\n",
    "    return pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57bb0f-a8c0-4290-b660-28f416850e60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Innitiate Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98a0e016-d95d-4a0a-ab50-de99bfaa4828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/18 22:53:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "spark = SparkSession.builder.appName(\"Cloud_Computing_Project\").getOrCreate()\n",
    "# sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ac309-96a0-49e0-8c4e-8c02bf65cc74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Data\n",
    "The data was obtained from kaggle:\n",
    "<br>\"Brazilian E-Commerce Public Dataset by Olist\"<br>\n",
    "https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/code?datasetId=55151&sortBy=voteCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c30af46-b926-4e21-a41f-ce5a40a71d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema_orders = StructType([\n",
    "    StructField(\"order_id\", StringType(), False),\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"order_status\", StringType(), True),\n",
    "    StructField(\"order_purchase_timestamp\", TimestampType(), True),\n",
    "    StructField(\"order_approved_at\", TimestampType(), True),\n",
    "    StructField(\"order_delivered_carrier_date\", TimestampType(), True),\n",
    "    StructField(\"order_delivered_customer_date\", TimestampType(), True),\n",
    "    StructField(\"order_estimated_delivery_date\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "schema_customers = StructType([\n",
    "    StructField(\"customer_id\", StringType(), False),\n",
    "    StructField(\"customer_unique_id\", StringType(), False),\n",
    "    StructField(\"customer_zip_code_prefix\", StringType(), True),\n",
    "    StructField(\"customer_city\", StringType(), True),\n",
    "    StructField(\"customer_state\", StringType(), True)\n",
    "])\n",
    "\n",
    "schema_geolocation = StructType([\n",
    "    StructField(\"geolocation_zip_code_prefix\", StringType(), False),\n",
    "    StructField(\"geolocation_lat\", DoubleType(), False),\n",
    "    StructField(\"geolocation_lng\", DoubleType(), False),\n",
    "    StructField(\"geolocation_city\", StringType(), True),\n",
    "    StructField(\"geolocation_state\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d08eb2ea-bab4-42bf-bc3d-6f48efb4366c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_orders = spark.read.option(\"header\", True).schema(schema_orders).csv('olist_orders_dataset.csv')\n",
    "df_customers = spark.read.option(\"header\", True).schema(schema_customers).csv('olist_customers_dataset.csv')\n",
    "df_geolocation = spark.read.option(\"header\", True).schema(schema_geolocation).csv('olist_geolocation_dataset.csv')\n",
    "# df_oitems = spark.read.option(\"header\", True).csv('olist_order_items_dataset.csv')\n",
    "# df_opayments = spark.read.option(\"header\", True).csv('olist_order_payments_dataset.csv')\n",
    "# df_oreviews = spark.read.option(\"header\", True).csv('olist_order_reviews_dataset.csv')\n",
    "# df_products = spark.read.option(\"header\", True).csv('olist_products_dataset.csv')\n",
    "# df_sellers = spark.read.option(\"header\", True).csv('olist_sellers_dataset.csv')\n",
    "# df_product_cat = spark.read.option(\"header\", True).csv('product_category_name_translation.csv')\n",
    "# df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637036b6-bc42-47d0-8b3f-d813c1903f3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16aa6375-695a-45a3-8b5e-324c69098231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      " |-- order_purchase_timestamp: timestamp (nullable = true)\n",
      " |-- order_approved_at: timestamp (nullable = true)\n",
      " |-- order_delivered_carrier_date: timestamp (nullable = true)\n",
      " |-- order_delivered_customer_date: timestamp (nullable = true)\n",
      " |-- order_estimated_delivery_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ab0e864-12b6-49fb-888f-9348389150ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_unique_id: string (nullable = true)\n",
      " |-- customer_zip_code_prefix: string (nullable = true)\n",
      " |-- customer_city: string (nullable = true)\n",
      " |-- customer_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "21932f23-0f22-416e-b1ea-389107132bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- geolocation_zip_code_prefix: string (nullable = true)\n",
      " |-- geolocation_lat: double (nullable = true)\n",
      " |-- geolocation_lng: double (nullable = true)\n",
      " |-- geolocation_city: string (nullable = true)\n",
      " |-- geolocation_state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_geolocation.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec898548-cbf4-4197-9873-20c770fccf4c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preprocessing\n",
    "includes:\n",
    "* Handling null values\n",
    "* Handling duplicated values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424f270-dea5-46ca-a9db-5ea7c20be02a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684cef90-98d5-4fd7-9be8-52a24cd9ba5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a3e6937-8c1e-4e0c-a976-07c769c6d3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                            0\n",
       "customer_id                         0\n",
       "order_status                        0\n",
       "order_purchase_timestamp            0\n",
       "order_approved_at                 160\n",
       "order_delivered_carrier_date     1783\n",
       "order_delivered_customer_date    2965\n",
       "order_estimated_delivery_date       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_pandas(df_orders).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5809824-5ad1-4d51-933a-d6af599e6736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id                 0\n",
       "customer_unique_id          0\n",
       "customer_zip_code_prefix    0\n",
       "customer_city               0\n",
       "customer_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "066e2a0f-61a8-4109-9716-603e85622658",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "geolocation_zip_code_prefix    0\n",
       "geolocation_lat                0\n",
       "geolocation_lng                0\n",
       "geolocation_city               0\n",
       "geolocation_state              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geolocation.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2233e25-47a0-4491-a1b9-4f89234ed2d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Drop null values\n",
    "Out of all tables, only orders table that contained null values. We will drop those rows since we have almost 100k of data, so it won't affect much in the analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0150d554-ae65-44f1-b3f0-1f01a81b870b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0\n",
       "customer_id                      0\n",
       "order_status                     0\n",
       "order_purchase_timestamp         0\n",
       "order_approved_at                0\n",
       "order_delivered_carrier_date     0\n",
       "order_delivered_customer_date    0\n",
       "order_estimated_delivery_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders = df_orders.dropna()\n",
    "convert_to_pandas(df_orders).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511b491-01f4-49a6-a8c9-f5228947c5fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Duplicates\n",
    "In this data, duplicates are rows with the same values in the key column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7925a7b3-0c39-48ad-8208-5b4e81d7056f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cheking Duplicated Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32d0dca2-92e6-41b3-b2ef-3000aee89e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|order_id|count|\n",
      "+--------+-----+\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orders \\\n",
    "    .groupby('order_id') \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "586cb2df-5b11-4a12-a427-96173420fbcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|customer_id|count|\n",
      "+-----------+-----+\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customers \\\n",
    "    .groupby('customer_id') \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f332765-1d0a-4b68-83a2-af06d2deb663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+\n",
      "|geolocation_zip_code_prefix|count|\n",
      "+---------------------------+-----+\n",
      "|24220                      |1146 |\n",
      "|24230                      |1102 |\n",
      "|38400                      |965  |\n",
      "|35500                      |907  |\n",
      "|11680                      |879  |\n",
      "|22631                      |832  |\n",
      "|30140                      |810  |\n",
      "|11740                      |788  |\n",
      "|38408                      |773  |\n",
      "|28970                      |743  |\n",
      "|36400                      |733  |\n",
      "|39400                      |724  |\n",
      "|37701                      |714  |\n",
      "|35162                      |713  |\n",
      "|35900                      |709  |\n",
      "|37200                      |696  |\n",
      "|88330                      |694  |\n",
      "|22790                      |687  |\n",
      "|35700                      |678  |\n",
      "|36570                      |667  |\n",
      "+---------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_geolocation \\\n",
    "    .groupby('geolocation_zip_code_prefix') \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c55aca-29e4-448a-b8f1-a7124783be93",
   "metadata": {},
   "source": [
    "### Drop duplicated values\n",
    "Out of all tables, only geolocation table that contained duplicated values. This duplicates came from the same zip code but slightly different coordinates (lat, lon). Therefore, we can safely drop the duplicated values so the coordinate for the same zip code will refer to the same coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "202e2f98-7d7a-467a-9cc9-4dc7e6035233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----+\n",
      "|geolocation_zip_code_prefix|count|\n",
      "+---------------------------+-----+\n",
      "+---------------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/19 02:24:11 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1067185 ms exceeds timeout 120000 ms\n",
      "23/10/19 02:24:11 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/10/19 02:24:12 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 02:24:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 02:57:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 02:57:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 03:10:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 03:10:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 03:27:49 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 03:27:49 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 03:59:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 03:59:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 04:16:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 04:16:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 04:29:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 04:29:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 05:02:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 05:02:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 05:18:29 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 05:18:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 05:35:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 05:35:38 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 06:08:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 06:08:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 06:26:02 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 06:26:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 07:00:33 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 07:00:33 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 07:18:11 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 07:18:11 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 07:33:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 07:33:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 08:06:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 08:06:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 08:24:32 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 08:24:32 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 08:58:50 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 08:58:50 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 09:14:59 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 09:14:59 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 09:47:23 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 09:47:23 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 10:04:19 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 10:04:19 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 10:19:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 10:19:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 10:53:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 10:53:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:08:39 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:08:39 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:22:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:22:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:22:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:22:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:22:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:22:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:22:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:22:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:22:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:22:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:23:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:23:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:23:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:23:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:23:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:23:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:24:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:24:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:24:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:24:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:24:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:25:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:25:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:25:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:25:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:26:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:26:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:26:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:26:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:26:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:26:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:27:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:27:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:27:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/10/19 11:27:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:27:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:28:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:28:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:834)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192-168-1-146.tpgi.com.au:50813\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/10/19 11:28:05 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n"
     ]
    }
   ],
   "source": [
    "df_geolocation = df_geolocation.dropDuplicates(['geolocation_zip_code_prefix'])\n",
    "\n",
    "df_geolocation \\\n",
    "    .groupby('geolocation_zip_code_prefix') \\\n",
    "    .count() \\\n",
    "    .where('count > 1') \\\n",
    "    .sort('count', ascending=False) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a51b7-5c4d-478c-b9b7-d1da59c265f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a360ea5-804e-4b89-b3e6-53d354c8b47a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creating Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e053d8fe-166a-43be-b9f9-66ba417fbb80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders = df_orders.withColumn(\"order_year\", year(\"order_purchase_timestamp\"))\n",
    "orders = orders.withColumn(\"order_month\", month(\"order_purchase_timestamp\"))\n",
    "\n",
    "orders.createOrReplaceTempView(\"orders\")\n",
    "df_customers.createOrReplaceTempView(\"customers\")\n",
    "df_geolocation.createOrReplaceTempView(\"geolocation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80cd2c-0516-4b96-ae35-d3a222ab236e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Managing Service Level Agreement (SLA)\n",
    "In most businesses, SLA often regarded as a metric which need to be monitored. The queries below can be used for several cases (examples provided within each section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93076364-4ddf-427f-984d-7273d1593345",
   "metadata": {},
   "source": [
    "### Maintaining Status\n",
    "Possible use cases:\n",
    "* Maintain the percentage of canceled order below certain number\n",
    "* Maintain the percentage of unavailable order below certain number\n",
    "* Maintain the percentage of delivered order above certain number\n",
    "* From the result, there are significant improvements on the percentage of canceled and delivered orders from 2016. What we did differently? Can we look back and learn from there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55f91829-90c6-4554-a1fd-a248b1a37967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+-----------------+\n",
      "|order_status|order_year|order_counts|order_percentage |\n",
      "+------------+----------+------------+-----------------+\n",
      "|canceled    |2016      |26          |7.90273556231003 |\n",
      "|delivered   |2016      |267         |81.15501519756839|\n",
      "|invoiced    |2016      |18          |5.47112462006079 |\n",
      "|processing  |2016      |2           |0.60790273556231 |\n",
      "|shipped     |2016      |9           |2.73556231003040 |\n",
      "|unavailable |2016      |7           |2.12765957446809 |\n",
      "|approved    |2017      |2           |0.00443449147469 |\n",
      "|canceled    |2017      |265         |0.58757012039644 |\n",
      "|created     |2017      |4           |0.00886898294938 |\n",
      "|delivered   |2017      |43428       |96.29054788142170|\n",
      "|invoiced    |2017      |175         |0.38801800403539 |\n",
      "|processing  |2017      |240         |0.53213897696282 |\n",
      "|shipped     |2017      |530         |1.17514024079289 |\n",
      "|unavailable |2017      |457         |1.01328130196670 |\n",
      "|canceled    |2018      |334         |0.61839254966581 |\n",
      "|created     |2018      |1           |0.00185147469960 |\n",
      "|delivered   |2018      |52783       |97.72638906889337|\n",
      "|invoiced    |2018      |121         |0.22402843865139 |\n",
      "|processing  |2018      |59          |0.10923700727630 |\n",
      "|shipped     |2018      |568         |1.05163762937179 |\n",
      "+------------+----------+------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status_per_year = spark.sql(\"\"\" \n",
    "SELECT \n",
    "    order_status, \n",
    "    order_year, \n",
    "    COUNT(*) as order_counts, \n",
    "    COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(PARTITION BY order_year) as order_percentage\n",
    "FROM orders\n",
    "GROUP BY order_year, order_status\n",
    "ORDER BY order_year, order_status\n",
    "\"\"\")\n",
    "status_per_year.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465e501-07be-4444-8e5d-acdcdd076db0",
   "metadata": {},
   "source": [
    "### Processing Time\n",
    "Possible use cases/questions to be answered:\n",
    "* Understanding and optimizing each processes\n",
    "* Understanding which process makes user need to wait longer\n",
    "* How long does a user need to wait until they received the product?\n",
    "* From the avg_purchase_estimation result, does it make sense to make users wait for almost a month? Assuming most transactions are within the country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "180e42ab-b13c-4a4d-a08c-fdb655abdae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+--------------------+-----------------------+---------------------+-----------------------+\n",
      "|avg_purchase_approved|avg_approved_carrier|avg_carrier_customer|avg_customer_estimation|avg_purchase_customer|avg_purchase_estimation|\n",
      "+---------------------+--------------------+--------------------+-----------------------+---------------------+-----------------------+\n",
      "|    0.518508073045195|   2.707191430092991|   9.282777921741383|     11.876881296902857|   12.497336125046644|     24.403948069709678|\n",
      "+---------------------+--------------------+--------------------+-----------------------+---------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_time = spark.sql(\"\"\" \n",
    "SELECT\n",
    "    AVG(DATEDIFF(order_approved_at, order_purchase_timestamp)) as avg_purchase_approved,\n",
    "    AVG(DATEDIFF(order_delivered_carrier_date, order_approved_at)) as avg_approved_carrier,\n",
    "    AVG(DATEDIFF(order_delivered_customer_date, order_delivered_carrier_date)) as avg_carrier_customer,\n",
    "    AVG(DATEDIFF(order_estimated_delivery_date, order_delivered_customer_date)) as avg_customer_estimation,\n",
    "    AVG(DATEDIFF(order_delivered_customer_date, order_purchase_timestamp)) as avg_purchase_customer,\n",
    "    AVG(DATEDIFF(order_estimated_delivery_date, order_purchase_timestamp)) as avg_purchase_estimation\n",
    "FROM orders\n",
    "\"\"\")\n",
    "process_time.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771d9ea-c143-4381-bca4-88a82c0cf803",
   "metadata": {},
   "source": [
    "### Estimation time\n",
    "Possible use cases/questions to be answered:\n",
    "* How accurate is the current estimation?\n",
    "* From the results, it's clear that the estimation need to be refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f6e0053-6586-478f-a71e-6b3adaf2d86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------+--------------+\n",
      "|delivered_on_time|delivered_early|delivered_late|\n",
      "+-----------------+---------------+--------------+\n",
      "|                0|          88649|          7827|\n",
      "+-----------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "estimation = spark.sql(\"\"\" \n",
    "SELECT\n",
    "    SUM(CASE WHEN order_delivered_customer_date = order_estimated_delivery_date THEN 1 ELSE 0 END) AS delivered_on_time,\n",
    "    SUM(CASE WHEN order_delivered_customer_date < order_estimated_delivery_date THEN 1 ELSE 0 END) AS delivered_early,\n",
    "    SUM(CASE WHEN order_delivered_customer_date > order_estimated_delivery_date THEN 1 ELSE 0 END) AS delivered_late\n",
    "FROM orders\n",
    "\"\"\")\n",
    "estimation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e20ab59-3df5-4e5f-bbcc-c6ec1265022c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Geospatial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e878032-e7a2-442d-816d-914860767fae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Number of Customers by States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19fbf87d-6f82-4ec8-95ed-de79e773301f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of customers by state'}, xlabel='state'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "customer_by_states = spark.sql(\"\"\" \n",
    "SELECT g.geolocation_state as state, COUNT(*) as counts\n",
    "FROM orders o\n",
    "LEFT JOIN customers c ON o.customer_id = c.customer_id\n",
    "LEFT JOIN geolocation g ON c.customer_zip_code_prefix = g.geolocation_zip_code_prefix\n",
    "GROUP BY state\n",
    "ORDER BY counts DESC\n",
    "\"\"\")\n",
    "# customer_by_states.show(truncate=False)\n",
    "customer_by_states.toPandas().plot(x='state', y='counts', kind='bar', title='Number of customers by state')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d72ec-3124-4849-a985-62cccc15390b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Number of Orders by States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ce15be7-7b95-4776-bdd4-333fc3611bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Number of purchase by state'}, xlabel='state'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT g.geolocation_state as state, COUNT(*) AS counts\n",
    "FROM orders o\n",
    "LEFT JOIN customers c ON o.customer_id = c.customer_id\n",
    "LEFT JOIN geolocation g ON c.customer_zip_code_prefix = g.geolocation_zip_code_prefix\n",
    "GROUP BY g.geolocation_state\n",
    "ORDER BY counts DESC\n",
    "\"\"\"\n",
    "\n",
    "order_by_state = spark.sql(query)\n",
    "# order_by_state.show()\n",
    "order_by_state.toPandas().plot(x='state', y='counts', kind='bar', title='Number of purchase by state')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fe544a-80b0-44be-a252-f016377e6016",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Monthly Orders by States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b0a784c7-4464-4281-8288-6f30d97a6f85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the year and month from the order_purchase_timestamp column\n",
    "orders = df_orders.withColumn(\"order_year\", year(\"order_purchase_timestamp\"))\n",
    "orders = orders.withColumn(\"order_month\", month(\"order_purchase_timestamp\"))\n",
    "\n",
    "# Join the orders DataFrame with customers and geolocation to get region information\n",
    "combined_df = orders.join(df_customers, \"customer_id\").join(df_geolocation, df_customers[\"customer_zip_code_prefix\"] == df_geolocation[\"geolocation_zip_code_prefix\"])\n",
    "\n",
    "# Group by year, month, and region, and count the number of orders\n",
    "monthly_orders = combined_df.groupBy(\"order_year\", \"order_month\", \"geolocation_state\").count()\n",
    "monthly_orders = monthly_orders.orderBy(asc(\"order_year\"), asc(\"order_month\"))\n",
    "\n",
    "# Convert the result to a Pandas DataFrame for plotting\n",
    "monthly_orders_df = monthly_orders.toPandas()\n",
    "\n",
    "# Create a plot for each region\n",
    "regions = monthly_orders_df[\"geolocation_state\"].unique()\n",
    "for region in regions:\n",
    "    region_data = monthly_orders_df[monthly_orders_df[\"geolocation_state\"] == region]\n",
    "    plt.plot(region_data[\"order_year\"].astype(str) + \"-\" + region_data[\"order_month\"].astype(str), region_data[\"count\"], label=region)\n",
    "\n",
    "# Set plot title and labels\n",
    "plt.title('Monthly Orders by State')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Display the plot\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for readability\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be548984-f7ea-469e-b8bb-6ae857050138",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Orders plot map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a65f930-1ab7-4fd8-9fe4-32c32e7baffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "order_coordinates = spark.sql(\"\"\" \n",
    "SELECT g.geolocation_lng as lon, g.geolocation_lat as lat, COUNT(*) as counts\n",
    "FROM orders o\n",
    "LEFT JOIN customers c ON o.customer_id = c.customer_id\n",
    "LEFT JOIN geolocation g ON c.customer_zip_code_prefix = g.geolocation_zip_code_prefix\n",
    "GROUP BY lon, lat\n",
    "\"\"\")\n",
    "# order_coordinates.show(truncate=False)\n",
    "order_coordinates = order_coordinates.toPandas()\n",
    "\n",
    "# Removing some outliers (orders outside of brazil)\n",
    "#Brazils most Northern spot is at 5 deg 16 27.8 N latitude.;\n",
    "order_coordinates = order_coordinates[order_coordinates.lat <= 5.27438888]\n",
    "#its most Western spot is at 73 deg, 58 58.19W Long.\n",
    "order_coordinates = order_coordinates[order_coordinates.lon >= -73.98283055]\n",
    "#Its most southern spot is at 33 deg, 45 04.21 S Latitude.\n",
    "order_coordinates = order_coordinates[order_coordinates.lat >= -33.75116944]\n",
    "#Its most Eastern spot is 34 deg, 47 35.33 W Long.\n",
    "order_coordinates = order_coordinates[order_coordinates.lon <=  -34.79314722]\n",
    "\n",
    "# obtain from https://geodata.lib.utexas.edu/catalog/stanford-px089rk5172\n",
    "sf = shp.Reader(\"BRA_adm0.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4899b6c4-76c1-4b0b-88fc-2e9ddc7498c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for shape in sf.shapeRecords():\n",
    "    x = [i[0] for i in shape.shape.points[:]]\n",
    "    y = [i[1] for i in shape.shape.points[:]]\n",
    "    plt.plot(x,y)\n",
    "    \n",
    "plt.scatter(order_coordinates.lon, order_coordinates.lat, \n",
    "            c=order_coordinates.counts,\n",
    "            marker = '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4bbf97-1a85-4d2d-be2d-58cecdda5101",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dumped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b35aec-1528-4a10-bc01-abd39329ff6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Checking the randomness of null data (delete soon)\n",
    "* need to plot null value with status and date to check ramdomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "476c71d8-4e68-41d7-a21a-46516887caaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|order_status|count|\n",
      "+------------+-----+\n",
      "|    canceled|  141|\n",
      "|     created|    5|\n",
      "|   delivered|   14|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_nulls = df_orders.filter(col(\"order_approved_at\").isNull())\n",
    "result = df_with_nulls.groupBy(\"order_status\").count()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff5dbe6d-ccac-4ca7-8251-4a0a865dd861",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|order_status|count|\n",
      "+------------+-----+\n",
      "|    canceled|  550|\n",
      "|    invoiced|  314|\n",
      "|     created|    5|\n",
      "| unavailable|  609|\n",
      "|  processing|  301|\n",
      "|    approved|    2|\n",
      "|   delivered|    2|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_nulls = df_orders.filter(col(\"order_delivered_carrier_date\").isNull())\n",
    "result = df_with_nulls.groupBy(\"order_status\").count()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8970ebb-a218-4fc1-8246-bebcf5117d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|order_status|count|\n",
      "+------------+-----+\n",
      "|     shipped| 1107|\n",
      "|    canceled|  619|\n",
      "|    invoiced|  314|\n",
      "|     created|    5|\n",
      "|   delivered|    8|\n",
      "| unavailable|  609|\n",
      "|  processing|  301|\n",
      "|    approved|    2|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_nulls = df_orders.filter(col(\"order_delivered_customer_date\").isNull())\n",
    "result = df_with_nulls.groupBy(\"order_status\").count()\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b16e395-3b65-4c22-8f3c-1fe0428c9203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['invoiced', 'shipped', 'processing', 'unavailable', 'canceled',\n",
       "       'delivered', 'created', 'approved'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df_orders.filter(\n",
    "    (df_orders.order_status != 'delivered') |\n",
    "    ((df_orders.order_status == 'delivered') &\n",
    "     (df_orders.order_approved_at.isNull() |\n",
    "      df_orders.order_delivered_carrier_date.isNull() |\n",
    "      df_orders.order_delivered_customer_date.isNull()))\n",
    ")\n",
    "convert_to_pandas(filtered_df)['order_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44fe83ca-d51d-417c-ae4f-1695c59871dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99441, 8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_pandas(df_orders).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9d09f1a-1f01-442c-b26d-49114325666e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders.filter((col(\"order_status\") == 'delivered') & \n",
    "                 (df_orders.order_approved_at.isNull() |\n",
    "                 df_orders.order_delivered_carrier_date.isNull() | \n",
    "                 df_orders.order_delivered_customer_date.isNull())\n",
    "                ).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "51e501c4-fa47-48e1-b2cb-ee51dc6f7967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2986, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_pandas(filtered_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "738d03f1-4101-46cc-aea8-ca05197f8d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                         0\n",
       "customer_id                      0\n",
       "order_status                     0\n",
       "order_purchase_timestamp         0\n",
       "order_approved_at                0\n",
       "order_delivered_carrier_date     0\n",
       "order_delivered_customer_date    0\n",
       "order_estimated_delivery_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered_df = df_orders.filter(\n",
    "#     ((col(\"order_status\") != 'delivered') &\n",
    "#      (~col('order_approved_at').isNull() |\n",
    "#       ~col('order_delivered_carrier_date').isNull() |\n",
    "#       ~col('order_delivered_customer_date').isNull()))\n",
    "# )\n",
    "filtered_df = df_orders.na.drop(\"any\")\n",
    "convert_to_pandas(filtered_df).shape\n",
    "\n",
    "convert_to_pandas(filtered_df).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7b89e-7a36-453d-8ef1-d6ae59213d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create aggregated data for BI tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438bca1d-c020-4c2f-81bc-f937e62c1fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------+----+-----+------------+\n",
      "|state|city                 |year|month|order_counts|\n",
      "+-----+---------------------+----+-----+------------+\n",
      "|SP   |taboao da serra      |2017|5    |1631        |\n",
      "|SP   |ferraz de vasconcelos|2018|3    |242         |\n",
      "|SP   |santos               |2018|3    |19419       |\n",
      "|SP   |sao vicente          |2017|12   |2256        |\n",
      "|SP   |cubatao              |2017|11   |711         |\n",
      "|SP   |cubatao              |2017|6    |296         |\n",
      "|SP   |jacarei              |2018|3    |894         |\n",
      "|SP   |bragana paulista    |2018|2    |198         |\n",
      "|SP   |sumar               |2018|6    |180         |\n",
      "|SP   |santa brbara d'oeste|2017|12   |125         |\n",
      "|SP   |araras               |2018|8    |1439        |\n",
      "|SP   |aguai                |2018|2    |164         |\n",
      "|SP   |so joo da boa vista|2018|6    |71          |\n",
      "|SP   |guatapara            |2018|4    |29          |\n",
      "|SP   |cristais paulista    |2017|4    |30          |\n",
      "|SP   |sorocaba             |2017|3    |1936        |\n",
      "|SP   |mairinque            |2018|4    |828         |\n",
      "|SP   |ibiuna               |2018|7    |591         |\n",
      "|SP   |avare                |2017|10   |49          |\n",
      "|SP   |presidente prudente  |2017|10   |482         |\n",
      "+-----+---------------------+----+-----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_cube = spark.sql(\"\"\" \n",
    "SELECT g.geolocation_state as state, g.geolocation_city as city, o.order_year as year, o.order_month as month, COUNT(*) as order_counts\n",
    "FROM orders o\n",
    "LEFT JOIN customers c ON o.customer_id = c.customer_id\n",
    "LEFT JOIN geolocation g ON c.customer_zip_code_prefix = g.geolocation_zip_code_prefix\n",
    "GROUP BY CUBE(state, city, year, month)\n",
    "\"\"\")\n",
    "\n",
    "data_cube.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e16a64-4e3e-4d0e-91fb-edd76070e333",
   "metadata": {},
   "source": [
    "## Create data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfd4f98-9324-43ae-be59-98ca8b3921e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cube.toPandas().to_csv('data_cube.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
